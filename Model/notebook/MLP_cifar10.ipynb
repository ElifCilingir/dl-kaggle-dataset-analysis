{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.datasets import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation=relu, input_dim=32*32*3))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation=relu))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation=relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation=relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation=relu))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation=softmax))\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=categorical_crossentropy,\n",
    "                  metrics=[categorical_accuracy])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshaping ...\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    (x_train, y_train), (x_val, y_val) = cifar10.load_data()\n",
    "\n",
    "    print(\"Before reshaping ...\")\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23137255 0.24313725 0.24705882 ... 0.48235294 0.36078431 0.28235294]\n",
      " [0.60392157 0.69411765 0.73333333 ... 0.56078431 0.52156863 0.56470588]\n",
      " [1.         1.         1.         ... 0.31372549 0.3372549  0.32941176]\n",
      " ...\n",
      " [0.1372549  0.69803922 0.92156863 ... 0.04705882 0.12156863 0.19607843]\n",
      " [0.74117647 0.82745098 0.94117647 ... 0.76470588 0.74509804 0.67058824]\n",
      " [0.89803922 0.89803922 0.9372549  ... 0.63921569 0.63921569 0.63137255]]\n",
      "After reshaping ...\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.compat.v1.keras.utils.to_categorical(y_train)\n",
    "y_val = tf.compat.v1.keras.utils.to_categorical(y_val)\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, 32 * 32 * 3)) / 255.0\n",
    "x_val = np.reshape(x_val, (-1, 32 * 32 * 3)) / 255.0\n",
    "\n",
    "print(x_train)\n",
    "print(\"After reshaping ...\")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,844,682\n",
      "Trainable params: 3,844,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 5s 109us/sample - loss: 2.0758 - categorical_accuracy: 0.2207 - val_loss: 1.8863 - val_categorical_accuracy: 0.3106\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.9221 - categorical_accuracy: 0.2921 - val_loss: 1.8408 - val_categorical_accuracy: 0.3439\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 4s 84us/sample - loss: 1.8728 - categorical_accuracy: 0.3147 - val_loss: 1.7925 - val_categorical_accuracy: 0.3516\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 4s 89us/sample - loss: 1.8483 - categorical_accuracy: 0.3259 - val_loss: 1.7820 - val_categorical_accuracy: 0.3780\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.8141 - categorical_accuracy: 0.3395 - val_loss: 1.7533 - val_categorical_accuracy: 0.3762\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 4s 86us/sample - loss: 1.7948 - categorical_accuracy: 0.3509 - val_loss: 1.7218 - val_categorical_accuracy: 0.3796\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.7747 - categorical_accuracy: 0.3610 - val_loss: 1.6801 - val_categorical_accuracy: 0.4040\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.7599 - categorical_accuracy: 0.3646 - val_loss: 1.7313 - val_categorical_accuracy: 0.3849\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.7489 - categorical_accuracy: 0.3671 - val_loss: 1.6518 - val_categorical_accuracy: 0.4136\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.7366 - categorical_accuracy: 0.3778 - val_loss: 1.6695 - val_categorical_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.7275 - categorical_accuracy: 0.3778 - val_loss: 1.6561 - val_categorical_accuracy: 0.4055\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.7169 - categorical_accuracy: 0.3815 - val_loss: 1.6211 - val_categorical_accuracy: 0.4296\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 1.7103 - categorical_accuracy: 0.3822 - val_loss: 1.6832 - val_categorical_accuracy: 0.3960\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.7084 - categorical_accuracy: 0.3850 - val_loss: 1.6201 - val_categorical_accuracy: 0.4304\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.6928 - categorical_accuracy: 0.3899 - val_loss: 1.6517 - val_categorical_accuracy: 0.4214\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.6890 - categorical_accuracy: 0.3941 - val_loss: 1.6003 - val_categorical_accuracy: 0.4279\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6828 - categorical_accuracy: 0.3950 - val_loss: 1.6025 - val_categorical_accuracy: 0.4399\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6840 - categorical_accuracy: 0.3970 - val_loss: 1.5985 - val_categorical_accuracy: 0.4373\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 1.6794 - categorical_accuracy: 0.3960 - val_loss: 1.5981 - val_categorical_accuracy: 0.4358\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 1.6729 - categorical_accuracy: 0.4000 - val_loss: 1.6058 - val_categorical_accuracy: 0.4394\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 4s 77us/sample - loss: 1.6638 - categorical_accuracy: 0.4004 - val_loss: 1.5952 - val_categorical_accuracy: 0.4418\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 1.6648 - categorical_accuracy: 0.4008 - val_loss: 1.5831 - val_categorical_accuracy: 0.4454\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.6577 - categorical_accuracy: 0.4069 - val_loss: 1.5917 - val_categorical_accuracy: 0.4345\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.6527 - categorical_accuracy: 0.4072 - val_loss: 1.5874 - val_categorical_accuracy: 0.4374\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.6518 - categorical_accuracy: 0.4092 - val_loss: 1.5653 - val_categorical_accuracy: 0.4480\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6521 - categorical_accuracy: 0.4100 - val_loss: 1.5885 - val_categorical_accuracy: 0.4390\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6427 - categorical_accuracy: 0.4115 - val_loss: 1.5798 - val_categorical_accuracy: 0.4388\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6394 - categorical_accuracy: 0.4130 - val_loss: 1.5832 - val_categorical_accuracy: 0.4363\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6369 - categorical_accuracy: 0.4119 - val_loss: 1.5807 - val_categorical_accuracy: 0.4360\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.6333 - categorical_accuracy: 0.4140 - val_loss: 1.5743 - val_categorical_accuracy: 0.4480\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6310 - categorical_accuracy: 0.4186 - val_loss: 1.5883 - val_categorical_accuracy: 0.4432\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.6265 - categorical_accuracy: 0.4167 - val_loss: 1.5579 - val_categorical_accuracy: 0.4488\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6167 - categorical_accuracy: 0.4229 - val_loss: 1.5546 - val_categorical_accuracy: 0.4529\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6146 - categorical_accuracy: 0.4235 - val_loss: 1.5665 - val_categorical_accuracy: 0.4544\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.6170 - categorical_accuracy: 0.4240 - val_loss: 1.5629 - val_categorical_accuracy: 0.4525\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.6179 - categorical_accuracy: 0.4208 - val_loss: 1.5563 - val_categorical_accuracy: 0.4520\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.6114 - categorical_accuracy: 0.4240 - val_loss: 1.5612 - val_categorical_accuracy: 0.4493\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.6172 - categorical_accuracy: 0.4212 - val_loss: 1.5421 - val_categorical_accuracy: 0.4564\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.6055 - categorical_accuracy: 0.4252 - val_loss: 1.5496 - val_categorical_accuracy: 0.4471\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.6073 - categorical_accuracy: 0.4280 - val_loss: 1.5341 - val_categorical_accuracy: 0.4551\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.6061 - categorical_accuracy: 0.4270 - val_loss: 1.5377 - val_categorical_accuracy: 0.4620\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5985 - categorical_accuracy: 0.4280 - val_loss: 1.5770 - val_categorical_accuracy: 0.4469\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.6004 - categorical_accuracy: 0.4318 - val_loss: 1.5287 - val_categorical_accuracy: 0.4599\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 1.6021 - categorical_accuracy: 0.4285 - val_loss: 1.5589 - val_categorical_accuracy: 0.4584\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.5970 - categorical_accuracy: 0.4281 - val_loss: 1.5641 - val_categorical_accuracy: 0.4556\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5941 - categorical_accuracy: 0.4335 - val_loss: 1.5442 - val_categorical_accuracy: 0.4583\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 4s 79us/sample - loss: 1.5905 - categorical_accuracy: 0.4323 - val_loss: 1.5482 - val_categorical_accuracy: 0.4623\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5881 - categorical_accuracy: 0.4324 - val_loss: 1.5456 - val_categorical_accuracy: 0.4632\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5829 - categorical_accuracy: 0.4332 - val_loss: 1.5205 - val_categorical_accuracy: 0.4648\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5826 - categorical_accuracy: 0.4349 - val_loss: 1.5384 - val_categorical_accuracy: 0.4578\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5762 - categorical_accuracy: 0.4385 - val_loss: 1.5466 - val_categorical_accuracy: 0.4482\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5802 - categorical_accuracy: 0.4347 - val_loss: 1.5342 - val_categorical_accuracy: 0.4595\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 4s 87us/sample - loss: 1.5804 - categorical_accuracy: 0.4363 - val_loss: 1.5292 - val_categorical_accuracy: 0.4679\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 4s 84us/sample - loss: 1.5792 - categorical_accuracy: 0.4388 - val_loss: 1.5145 - val_categorical_accuracy: 0.4713\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 4s 84us/sample - loss: 1.5760 - categorical_accuracy: 0.4367 - val_loss: 1.5123 - val_categorical_accuracy: 0.4689\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5711 - categorical_accuracy: 0.4404 - val_loss: 1.5164 - val_categorical_accuracy: 0.4705\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 4s 86us/sample - loss: 1.5733 - categorical_accuracy: 0.4411 - val_loss: 1.5057 - val_categorical_accuracy: 0.4744\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 4s 87us/sample - loss: 1.5760 - categorical_accuracy: 0.4379 - val_loss: 1.5428 - val_categorical_accuracy: 0.4679\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 4s 86us/sample - loss: 1.5727 - categorical_accuracy: 0.4384 - val_loss: 1.5167 - val_categorical_accuracy: 0.4661\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5739 - categorical_accuracy: 0.4389 - val_loss: 1.5204 - val_categorical_accuracy: 0.4637\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5587 - categorical_accuracy: 0.4431 - val_loss: 1.5378 - val_categorical_accuracy: 0.4616\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5674 - categorical_accuracy: 0.4404 - val_loss: 1.5159 - val_categorical_accuracy: 0.4700\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 4s 84us/sample - loss: 1.5628 - categorical_accuracy: 0.4435 - val_loss: 1.5168 - val_categorical_accuracy: 0.4681\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5607 - categorical_accuracy: 0.4442 - val_loss: 1.5145 - val_categorical_accuracy: 0.4712\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5649 - categorical_accuracy: 0.4412 - val_loss: 1.5798 - val_categorical_accuracy: 0.4406\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 4s 84us/sample - loss: 1.5595 - categorical_accuracy: 0.4418 - val_loss: 1.4978 - val_categorical_accuracy: 0.4738\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5627 - categorical_accuracy: 0.4434 - val_loss: 1.5167 - val_categorical_accuracy: 0.4737\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 4s 82us/sample - loss: 1.5565 - categorical_accuracy: 0.4485 - val_loss: 1.5321 - val_categorical_accuracy: 0.4609\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5584 - categorical_accuracy: 0.4444 - val_loss: 1.5210 - val_categorical_accuracy: 0.4730\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5538 - categorical_accuracy: 0.4460 - val_loss: 1.5248 - val_categorical_accuracy: 0.4567\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 1.5536 - categorical_accuracy: 0.4475 - val_loss: 1.5018 - val_categorical_accuracy: 0.4754\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5512 - categorical_accuracy: 0.4501 - val_loss: 1.5065 - val_categorical_accuracy: 0.4740\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 4s 86us/sample - loss: 1.5484 - categorical_accuracy: 0.4501 - val_loss: 1.5358 - val_categorical_accuracy: 0.4684\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 4s 87us/sample - loss: 1.5471 - categorical_accuracy: 0.4489 - val_loss: 1.4997 - val_categorical_accuracy: 0.4784\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 1.5530 - categorical_accuracy: 0.4472 - val_loss: 1.5034 - val_categorical_accuracy: 0.4816\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5464 - categorical_accuracy: 0.4494 - val_loss: 1.5158 - val_categorical_accuracy: 0.4615\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5477 - categorical_accuracy: 0.4467 - val_loss: 1.5069 - val_categorical_accuracy: 0.4754\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5470 - categorical_accuracy: 0.4512 - val_loss: 1.5132 - val_categorical_accuracy: 0.4708\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 1.5437 - categorical_accuracy: 0.4529 - val_loss: 1.4987 - val_categorical_accuracy: 0.4735\n",
      "Epoch 80/200\n",
      "17664/50000 [=========>....................] - ETA: 2s - loss: 1.5332 - categorical_accuracy: 0.4507"
     ]
    }
   ],
   "source": [
    "m = create_model()\n",
    "print(m.summary())\n",
    "\n",
    "history = m.fit(x_train, y_train,\n",
    "                validation_data=(x_val, y_val),\n",
    "                epochs=200,\n",
    "                batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'], label='categorical_accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
